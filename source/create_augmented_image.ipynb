{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 1 Import libraries + custom functions\n",
    "\n",
    "import numpy as np\n",
    "from utils import filename_from_path\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "import keras\n",
    "import glob\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "def reshape_to_view_img(img):\n",
    "    (x,y) = (img.shape[0],img.shape[1])\n",
    "    return np.reshape(img,(x,-1,))\n",
    "\n",
    "def filename_from_path(path):\n",
    "    return path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17321119024075214032\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#verify GPU is up n running\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Load data + initialize variables\n",
    "\n",
    "train_labels = pd.read_csv('train_onelabel.csv',index_col='image')\n",
    "get_class_of = train_labels['class'].to_dict()                                             #dict image->class\n",
    "get_images_of = train_labels.groupby('class').apply(lambda x: x.values.tolist()).to_dict() #dict ???\n",
    "\n",
    "input_size = (64, 64)\n",
    "output_size = len(list(train_labels['class'].unique()))\n",
    "\n",
    "label_map = pd.read_csv('label_map.txt',header=None,names=['name','id'],sep=' ')\n",
    "get_name_of_class = label_map['name'].to_dict()\n",
    "''' get_name_of_class[9] >> 'ctenophore_cydippid_tentacles' '''\n",
    "get_class_name_of = {v: k for k, v in get_name_of_class.items()}\n",
    "''' get_class_name_of['ctenophore_cydippid_tentacles'] >> 9 '''\n",
    "\n",
    "training_paths_list = glob.glob('competition_data/train_images/*')     #normal (not numpy) list of str  \n",
    "test_set_list = glob.glob('competition_data/test_images/*')          #normal (not numpy) list of str \n",
    "\n",
    "# savedmodelpath = 'trainHistory/12-08 18.54, train_err=0.70, test_err=0.73double_kernel_size_termatismeno.h5'\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "#model parameters\n",
    "\n",
    "batch_size=64\n",
    "reg_lambda = 0.01/255\n",
    "dropout_value=0.25\n",
    "\n",
    "#handle imbalanced classes\n",
    "\n",
    "#Read training data\n",
    "\n",
    "class_counts = train_labels['class'].value_counts()\n",
    "class_weights = 1/np.log(class_counts)\n",
    "#class_weights = class_weights.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Load & Preprocess input data\n",
    "\n",
    "def inverse_grayscale(pixel_value):\n",
    "    return (255.-pixel_value)\n",
    "def inverse_scale_center(pixel_value):\n",
    "    return (((255.-pixel_value)/255)-0.5)\n",
    "v_inverse_grayscale = np.vectorize(inverse_grayscale)\n",
    "v_inverse_scale_center = np.vectorize(inverse_scale_center)\n",
    "\n",
    "input_size = (64,64)      # ! parameter\n",
    "training_images = (load_img(p, target_size=input_size, grayscale=True) for p in training_paths_list)\n",
    "traning_images_array = np.array([img_to_array(im) for im in training_images]) #numpy array of numpy arrays (pictures) (X_train)\n",
    "del training_images\n",
    "\n",
    "test_images = (load_img(p, target_size=input_size,grayscale=True) for p in test_set_list)\n",
    "test_images_array = np.array([img_to_array(im) for im in test_images])\n",
    "del test_images\n",
    "\n",
    "if (platform.system()=='Windows'):\n",
    "    all_labels = list(map(lambda p: get_class_of[p.split('\\\\')[-1]] , training_paths_list))\n",
    "else:\n",
    "    all_labels = list(map(lambda p: get_class_of[p.split('/')[-1]] , training_paths_list))\n",
    "\n",
    "traning_images_array = v_inverse_scale_center(traning_images_array)   #apply inverse grayscale transformation before splitting to train+validation\n",
    "test_images_array = v_inverse_scale_center(test_images_array)         #apply inverse grayscale transformation to test data as well\n",
    "\n",
    "#We will take ALL images for the final training - normally we split 80-20 (train-validation)\n",
    "# traning_images_array, validation_images_array, train_labels , validation_labels = train_test_split(traning_images_array, \n",
    "#                                                                                                    to_categorical(all_labels), \n",
    "#                                                                                                    stratify=to_categorical(all_labels), \n",
    "#                                                                                                    test_size=0.2, random_state=41)\n",
    "\n",
    "#split training and cross validation data\n",
    "\n",
    "traning_images_array = traning_images_array.astype('float32')\n",
    "# validation_images_array = validation_images_array.astype('float32')\n",
    "test_images_array = test_images_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation\n",
    "train_datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                   featurewise_center=True,\n",
    "                                   featurewise_std_normalization=True,\n",
    "                                    samplewise_std_normalization=False,\n",
    "                                    samplewise_center=False,\n",
    "                                   #rescale=1./255.,\n",
    "                                   #zca_whitening=True,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=False,\n",
    "                                   zoom_range=0.1,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = (20/360)*(2*np.pi)\n",
    "                                )\n",
    "\n",
    "\n",
    "# valid_datagen = ImageDataGenerator(\n",
    "#             featurewise_center=True,\n",
    "#             featurewise_std_normalization=True,\n",
    "#             samplewise_std_normalization=False,\n",
    "#             samplewise_center=False,\n",
    "#         )\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            samplewise_std_normalization=False,\n",
    "            samplewise_center=False,\n",
    "        )\n",
    "\n",
    "\n",
    "train_datagen.fit(traning_images_array)    #used for zca whitening/featurewise_center & normalization\n",
    "# valid_datagen.fit(validation_images_array)\n",
    "test_datagen.fit(test_images_array)\n",
    "\n",
    "###\n",
    "savepath = 'augmented_shit2//'\n",
    "\n",
    "img = load_img('competition_data/train_images/419.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in train_datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=savepath, save_prefix='newshit', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
